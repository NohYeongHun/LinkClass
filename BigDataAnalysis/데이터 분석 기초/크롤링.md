# 크롤링
1. 크롬 브라우저에서 웹 페이지의 HTML 확인
- 원하는 정보를 찾기 위해서는 크롬 개발자 도구 활용
- ex)[melon]http://www.melon.com/chart/index.htm
- 브라우저의 메뉴버튼-[도구더보기]- [개발자도구]또는 F12 키 또는 마우스 오른쪽 버튼-[검사]

## BeautifulSoup
1. BeautifulSoup 라이브러리
- 문자열 데이터를 html 형식으로 읽고 정보를 쉽게 찾을 수 있음
- html 문자열을 BeautifulSoup으로 해석하기
- #bs4 패키지 내의 BeautifulSoup 라이브러리 불러오기<br>
from bs4 import BeautifulSoup

2. 태그 선택을 위한 조건 방법
- id 값과 class 명을 이용해 태그 찾기 예
- 조건 부분에 #id값 또는 .class명 넣어 찾기
ids_fruits1 = soup.select('#fruits1')
class_price =  soup.select('.price')
tags_span_class_price = soup.select('span.price')

3. 상위 구조 활용
- 태그 속성만으로 찾기 어려운 경우 사용
- 어떤 부모 태그 아래 있는지 등의 정보를 추가하여 검색
- 한 단게 아래를 지정시에는 > 기호 사용
- 상위 태그 : 부모 태그, 하위 태그 : 자식 태그
- 1개 이상의 여러 단계 아래를 지정 시 띄어스기(빈 칸) 사용
- 상위 태그 : 부모 태그, 하위 태그 : 자손 태그
- 태그 구조로 위치 찾기 예
- 바나나 검색
<br> tags_name = soup.select('span.name')
- 파인애플 제외 바나나 찾기
<br> 바나나가 속한 부모 태그 정보 추가<br>
tags_banana1 = soup.select('#fruits1 > span.name')

4. 정보 가져오기(1) - 태그 그룹에서 하나의 태그 선택

- soup.select('조건'): 조건에 해당하는 모든 태그 찾음 => 그룹 형태로 결과 확인
- 태그 그룹에서 개별 태그에 접근하기 위해서는<br>
인덱스 번호를 활용<br>
반복문<br>

```python
tags = soup.select('span.name')
for tag in tags: # 반복문으로 태그 그룹에서 각각의 태그 선택하여 활용하기
    print(tag)사용
```

- html 변수에 들어있는 문자열 정보를 html 형식으로 해석<br>
soup = BeautifulSoup(html, 'html.parser')

5. 정보 가져오기(2) - 선택한 태그에서 정보 가져오기
- 인덱스 번호나 반복문을 활용해 원하는 태그 선택 후<br>
화면에 보이는 글 부분을 가져오거나(.text) => 브라우저에 표시되는 정보를 수집하는 일이 많기에.<br>
태그 내 속성 값을 가져옴(['속성명'])<br>
화면에 보이지 않는 URL 주소를 수집하기 위해['href']도 필요<br>
하이퍼 링크는 <a href ='URL주소'>로 이루어짐.

6. 멜론 노래 순위 정보 크롤링
- 인기 차트 상위 100 곡 정보 크롤링
- 크롤링 단계
크롬 드라이버 실행 => 크롬 브라우저 열기<br>
멜론 인기차트 웹페이지 접속M<br>
HTML 다운로드 및 BeautifulSoup 읽기<br>
변수 soup 노래 정보 포함하는 태그 찾기<br>
F12키 -> 라일락 노래에 마우스 포인터 이동 -> 오른쪽 마우스 버튼 -> 검사

7. 멜론 노래 순위 정보 크롤링
- 크롤링 단계(계속)
- 노래 한 곡의 정보를 가지는 태그 <table> 아래 <tbody> 아래 <tr>
- 노래 태그 찾기<br>
soup.select(‘table > tbody > tr') : table 태그 아래 tbody 태그 아래 tr 태그 모두 찾기<br>
len(songs) : 해당 원소가 몇 개인지 확인 => 해당 조건을 만족하는 태그는 100개<br>
songs[0] : 선택된 태그 중 첫 번째 태그를 화면에 출력<br>

```python
# 멜론 100위 노래순위 정보 검색.
for song in songs:
    title = song.select('div.ellipsis.rank01 > span >a')[0].text
    singer = song.select('div.ellipsis.rank02 > span >a')[0].text
    print(title, singer, sep =' | ')

# 멜론 인기차트 상위 100곡 크롤링(정리)

# from selenium import webdriver
driver = webdriver.Chrome('chromedriver.exe')

url = 'http://www.melon.com/chart/index.htm'
driver.get(url)

# from bs4 import BeautifulSoup
html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

songs = soup.select('tbody > tr')

for song in songs:
    title = song.select('div.ellipsis.rank01 > span >a')[0].text
    singer = song.select('div.ellipsis.rank02 > span >a')[0].text
    print(title, singer, sep =' | ')
```

## selenium만을 활용한 크롤링
1. 앞에서 실행하는 크롤링은 +BeautifulSoup으로 원하는 정보 가져오는 방식
- 예: soup.select('tbody > tr')

2. 원하는 정보를 가져오는 다른 방식
- 태그 구조 정보인 CSS Selector 사용하는 방식
- driver.find_elements_by_css_selector('조건') : 원하는 조건에 해당하는 태그를 모두 찾아옴.
- 조건 : 태그명, class명, id 값, 부모 태그 등의 구조 정보 지정 => BeautifulSoup에서 작성하는 방식과 동일

- 웹페이지에 계속 접속한 상태로 정보를 가져옴
- html = driver.page_source HTML 정보를 다운로드하는 과정은 필요 없음
- BeautifulSoup을 같이 사용
- selenium 만을 사용하는 경우에는 웹 페이지에 계속 접속
- 권장 방법<br>
selenium을 이용해 원하는 웹 페이지에 접속하고 값을 입력하거나 클릭하는 등의 작업 진행<br>
필요한 정보가 나타났을 때에는 HTML을 다운로드 한 뒤 필요 정보 추출<br>


## HTML 구조
1. 페이지 다운로드 후 필요한 정보 위치 파악 필요
2. 즉, 특정 정보가 존재하는 위치를 지정 가능해야 함
3. 규칙
4. 시작과 끝 존재
- <태그> ....<태그>
- 태그의 시작과 끝 사이에 화면에 표시되는 정보 존재
- 태그가 속성을 가질 수 있음.

5. 정보 찾기 - 태그 속성 활용
- BeautifulSoup 명령어 select() 사용
- select('조건') : html 내에서 입력한 조건을 만족하는 태그 모두 선택
- 조건
해당 태그의 태그명이나 속성값 지정<br>
태그 간의 구조 지정<br>
두 방법 모두 활용<br>




