# 선형 회귀
- 종속변수 y와 한 개 이상의 독립 변수 X와의 선형 상관 관계를 모델링하는 회귀분석 기법
- 한 개의 설명 변수에 기반한 경우는 단순 선형 회귀, 둘 이상의 설명 변수에 기반한 경우에는 다중 선형 회귀
- 무게 = a(기울기)* 길이 + b(절편)
## 최적의 직선 방정식을 어떻게 구하는가?
- a를 증가할것인가? 감소할것인가? (미분)
- 얼마만큼 증가하게 정할 것인가? => 학습율
- 기울기가 0인점을 찾는다.

# 다항 회귀

```python
train_poly = np.column_stack((train_input ** 2, train_input))
test_poly = np.column_stack((test_input ** 2, test_input))
```

# 다중 회귀
- 단순 선형회귀(길이 특성 하나만 사용)
- 다항 선형회귀(길이 특성을 여러 번 사용)
- 여러 특성 사용
- Multiple Regression 또는 Multinomial Regreesion
- 특성이 2개이면 평면
- 특성이 3개 이상이면 표현 어려움
- 여러 특성을제곱등 변형해서 새로운 특성을 만들어서 사용(특성 공학[Feature Engineering])
- 길이, 높이, 두께 등 여러 개의 특성을 사용해 예측

## 훈련, 테스트 데이터 셋 나누기

```python
# 난수 시드를 42로 고정.
# 실행시마다 동일한 시퀀스가 나와야 결과값을 비교할 수 있다.
from sklearn.model_selection import train_test_split
train_input,test_input, train_target, test_target,
train_test_split(perch_full, perch_Weight, random_state=42)
```

## 다항 특성 만들기
- scikit-learn 라이브러리는 특성을 만들거나 전처리하기 위한 다양한 클래스를 제공
- 이런 클래스를 변환기라고 부름
- transformer는 일관되게, fit()과 transform() 메소드를 제공

- 항상, fit() 한 후에 transform()을 해야함 두 메소드를 하나로 한 fit_transform()

```python
poly = PolynomialFreatures()
print(poly.fit_transform([[2,3]]))
[[1,2,3,4,5,6]]
```

## Transformer와 Estimator
- Scikit-learn 라이브러리는 특성을 만들거나 전처리하기 위한 다양한 클래스 제공
- 이런 클래스를 변환기라고 부름.
- 대표적으로, sklearn.preprocessing.PolynomialFeatures
- transformer는 일관되게, fit()과 transform() 메소드를 제공

# 규제, 일반화, 정규화
- 규제는 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 훼방하는 것, Overfitting을 줄이는 용도 사용
- 선형 회귀 모델의 경우, 트것ㅇ에 곱해지는 계수(기울기, 가중치)의 크기를 작게 만드는 것
- Overfitting 되었다는 것은 모델로 그래프를 그렸을 때 너무 구불구불 하다는 것이고, 구불구불한 이유는 모델의 차수가 크기 때문
- 1차 함수보다 2차함수가, 3차 함수가 그리고 4차함수 ..n차 함수로 갈수록 그래프가 구불구불해지는것.

# 규제(Regularization)전에 표준화(Standardization)
- 선형 회귀는 특성에 대해 스케일 조정(표준 점수화)이 필요 없었음.
- 그러나, 규제의 경우에는 특성의 스케일(scale)을 맞출 필요가 있음 -표준화
- KNN 예제에서 표준 점수(Z score)로 변환 공식에 따라 변환

# 릿지(Ridge) 회귀
- Ridge는 계수(가중치)를 제곱한 값을 기준으로 규제(벌칙)을 적용 일반적으로 Ridge를 더 선호함

# 적절한 규제 강도 찾기


## 라쏘 회귀
- Ridge는 계수(가중치)를 제곱한 값을 기준으로 규제(벌칙)을 적용
- Lasso는 계수(가중치)의 절대값을 기준으로 규제(벌칙)을 적용
